{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "# Name:         main.py\n",
    "# Purpose:      Open Project Fall - 2022: Predict mortality with medical data\n",
    "#               CodaLab competition: https://competitions.codalab.org/competitions/27605#learn_the_details\n",
    "#\n",
    "# Author(s):    David Little\n",
    "#\n",
    "# Created:      12/17/2021\n",
    "# Updated:      12/17/2021\n",
    "# Update Comment(s):\n",
    "#\n",
    "# TO DO:\n",
    "#\n",
    "# FUTURE WORK:\n",
    "#\n",
    "# BUGS TO FIX:\n",
    "#\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(123)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "python_random.seed(123)\n",
    "\n",
    "# The below set_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _______________________ Import __________________________________________________________\n",
    "all_data = pd.read_csv('mimic_synthetic_train.csv', delimiter=' ', header=None)\n",
    "col_names = pd.read_csv('mimic_synthetic_feat.csv', delimiter=' ', header=None)\n",
    "all_data = all_data.iloc[:,1:]\n",
    "all_data.set_axis(col_names, axis=1, inplace=True)\n",
    "\n",
    "labels = pd.read_csv('mimic_synthetic_train_labels.csv', delimiter=' ', header=None)\n",
    "all_data['DIED'] = labels\n",
    "all_data.dropna(inplace=True)\n",
    "all_data = all_data.reset_index().iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _______________________ Identify constant columns_________________________________\n",
    "non_dups = []\n",
    "for column in all_data:\n",
    "    if all_data[column].unique().size == 1:\n",
    "        non_dups.append(column)\n",
    "\n",
    "all_data.drop(non_dups, axis=1, inplace=True)\n",
    "\n",
    "# _______________________ Drop non-informative _________________________________\n",
    "all_data = all_data.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _______________________ Just the categorical _________________________________\n",
    "\n",
    "categorical_variables = all_data.select_dtypes(include='O').keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _______________________ Feature Selection _________________________________\n",
    "\n",
    "# Creating copy of data and performing label encoding on categorical data\n",
    "\n",
    "temp_data = all_data.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in categorical_variables:\n",
    "    temp_data[column] = label_encoder.fit_transform(temp_data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHI Squared Test for Categorical Data\n",
    "\n",
    "X = temp_data[categorical_variables]\n",
    "y = temp_data.iloc[:,-1]\n",
    "\n",
    "p_score = chi2(X,y)\n",
    "\n",
    "feat_p_values = pd.DataFrame({'Specs': X.columns, 'P_Value': p_score[1]})\n",
    "feat_p_values = feat_p_values.sort_values(by=['P_Value'])\n",
    "feat_p_values = feat_p_values.reset_index().drop('index', axis=1)\n",
    "unwanted_categorical_features = list(feat_p_values[feat_p_values['P_Value']>0.01]['Specs'])\n",
    "\n",
    "# unwanted_categorical_features = categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA Test for Numerical Features\n",
    "\n",
    "X = temp_data.iloc[:,:164]\n",
    "y = temp_data.iloc[:,-1]\n",
    "\n",
    "X.drop(categorical_variables, axis=1, inplace=True)\n",
    "\n",
    "f_score = f_classif(X,y)\n",
    "\n",
    "feat_f_values = pd.DataFrame({'Specs': X.columns, 'F_Value': f_score[1]})\n",
    "feat_f_values = feat_f_values.sort_values(by=['F_Value'])\n",
    "feat_f_values = feat_f_values.reset_index().drop('index', axis=1)\n",
    "unwanted_numerical_features = list(feat_f_values[feat_f_values['F_Value']>0.01]['Specs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying feature selection\n",
    "\n",
    "# all_data.drop(unwanted_numerical_features, axis=1, inplace=True)\n",
    "# all_data.drop(unwanted_categorical_features, axis=1, inplace=True)\n",
    "# categorical_variables = categorical_variables.drop(unwanted_categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aksha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aksha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#____________________________ One-hot encoding______________________\n",
    "\n",
    "cats = all_data[categorical_variables]\n",
    "all_data.drop(cats, axis=1, inplace=True)\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "# Fit encoding\n",
    "enc.fit(cats)\n",
    "# Make conversion\n",
    "feat = enc.transform(cats).toarray()\n",
    "feat_names = enc.get_feature_names()\n",
    "cat_data = pd.DataFrame(feat, columns=feat_names)\n",
    "\n",
    "all_data = pd.concat([cat_data,all_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_______________________test_train split_________________________________________\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_data.iloc[:,:-1], all_data['DIED'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________ Upsampling _________________________________\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "all_data_train = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "ones = all_data_train[all_data_train['DIED'] == 1]\n",
    "zeros = all_data_train[all_data_train['DIED'] == 0]\n",
    "\n",
    "upsampled = resample(ones, n_samples=len(zeros), replace=True, random_state=42)\n",
    "all_data_train = pd.concat([zeros,upsampled], axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1931/1931 [==============================] - 7s 3ms/step - loss: 0.7621 - accuracy: 0.6307\n",
      "Epoch 2/25\n",
      "1931/1931 [==============================] - 5s 3ms/step - loss: 0.5809 - accuracy: 0.7007\n",
      "Epoch 3/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.5565 - accuracy: 0.7220\n",
      "Epoch 4/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.5417 - accuracy: 0.7335\n",
      "Epoch 5/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.5321 - accuracy: 0.7412\n",
      "Epoch 6/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.5233 - accuracy: 0.7487\n",
      "Epoch 7/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.5149 - accuracy: 0.7551\n",
      "Epoch 8/25\n",
      "1931/1931 [==============================] - 5s 3ms/step - loss: 0.5023 - accuracy: 0.7618\n",
      "Epoch 9/25\n",
      "1931/1931 [==============================] - 5s 3ms/step - loss: 0.4961 - accuracy: 0.7668\n",
      "Epoch 10/25\n",
      "1931/1931 [==============================] - 5s 3ms/step - loss: 0.4858 - accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4793 - accuracy: 0.7762\n",
      "Epoch 12/25\n",
      "1931/1931 [==============================] - 5s 3ms/step - loss: 0.4714 - accuracy: 0.7806\n",
      "Epoch 13/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4656 - accuracy: 0.7832\n",
      "Epoch 14/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4604 - accuracy: 0.7869\n",
      "Epoch 15/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4533 - accuracy: 0.7909\n",
      "Epoch 16/25\n",
      "1931/1931 [==============================] - 7s 4ms/step - loss: 0.4454 - accuracy: 0.7960\n",
      "Epoch 17/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4408 - accuracy: 0.7999\n",
      "Epoch 18/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4372 - accuracy: 0.8005\n",
      "Epoch 19/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4299 - accuracy: 0.8039\n",
      "Epoch 20/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4264 - accuracy: 0.8063\n",
      "Epoch 21/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4236 - accuracy: 0.8091\n",
      "Epoch 22/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4188 - accuracy: 0.8116\n",
      "Epoch 23/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4142 - accuracy: 0.8144\n",
      "Epoch 24/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4123 - accuracy: 0.8165\n",
      "Epoch 25/25\n",
      "1931/1931 [==============================] - 6s 3ms/step - loss: 0.4100 - accuracy: 0.8169\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(305, input_dim=305, activation='relu'))\n",
    "model.add(Dense(230, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(all_data_train.iloc[:, :-1], all_data_train['DIED'], epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.19703342926721273\n",
      "Accuracy: 0.773284160520065\n",
      "Balanced Accuracy: 0.7684776639892644\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "preds = [0 if pred < 0.5 else 1 for pred in preds]\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, preds)\n",
    "    \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, preds)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "bal_acc = balanced_accuracy_score(y_test, preds)\n",
    "\n",
    "print('F1 Score:', f1)\n",
    "print('Accuracy:', acc)\n",
    "print('Balanced Accuracy:', bal_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aksha\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#______________________________________ Predict test case & save _________________________________________\n",
    "test_data = pd.read_csv('mimic_synthetic_test.csv', delimiter=' ', header=None)\n",
    "col_names = pd.read_csv('mimic_synthetic_feat.csv', delimiter=' ', header=None)\n",
    "test_data = test_data.iloc[:,1:]\n",
    "test_data.set_axis(col_names, axis=1, inplace=True)\n",
    "test_data.fillna('0', inplace=True)\n",
    "\n",
    "test_data.drop(non_dups, axis=1, inplace=True)\n",
    "\n",
    "# _______________________ Drop non-informative _________________________________\n",
    "test_data = test_data.iloc[:,4:]\n",
    "\n",
    "# # _________________________ Feature Selection __________________________________\n",
    "\n",
    "# test_data.drop(unwanted_numerical_features, axis=1, inplace=True)\n",
    "# test_data.drop(unwanted_categorical_features, axis=1, inplace=True)\n",
    "\n",
    "# _______________________ Just the categorical _________________________________\n",
    "\n",
    "cats = test_data[categorical_variables]\n",
    "test_data.drop(cats, axis=1, inplace=True)\n",
    "\n",
    "#____________________________ One-hot encoding_________________________________\n",
    "\n",
    "feat = enc.transform(cats).toarray()\n",
    "feat_names = enc.get_feature_names()\n",
    "cat_data = pd.DataFrame(feat, columns=feat_names)\n",
    "\n",
    "#______________________________ Make prediction_________________________________\n",
    "test_data = pd.concat([cat_data,test_data], axis=1)\n",
    "\n",
    "test_data = test_data.astype('float')\n",
    "\n",
    "preds = model.predict(test_data)\n",
    "preds = [0 if pred < 0.5 else 1 for pred in preds]\n",
    "\n",
    "np.savetxt(\"mimic_synthetic_test_prediction.csv\", preds, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
